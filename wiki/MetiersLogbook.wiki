#Assign one métier to each logbook event.

= Introduction =

WP2 goal was to investigate a range of multivariate statistical methods and to develop a tool selecting the most appropriate one for assigning one métier to each logbook event. This tool allows defining métiers at DCF Level7 and aggregates them into the DCF Level5.

Logbooks data are the main source of data for getting information on the fishing activities. From logbooks data, information of EU level gear type and selectivity feature of the gear are directly available. However, fishers do not declare which species they are actually targeting when fishing, and therefore the DCF Level5 and the more precise DCF Level7, expected to reflect the fishing intention, has to be inferred from the available data, and in particular the catch data. Following, the ICES (2003) recommendation, analyses have been performed on landings composition expressed in cash value as this may reflect more accurately the actual targeting choices of the fishermen.

The work consisted in designing several sequential steps to have a complete tool firstly allowing identifying métiers from logbooks raw data and then assigning a métier to a new dataset.
These sequential steps aim at:

i) Identifying the main species out of all species recorded and reducing the dataset to these key species only (Step 1). These key species are selected from the application of three different filtering methods.

ii) Choosing to run or not a PCA to increase the quality of the final classification (PCA is likely to discard potential irrelevant information) (Step 2).

iii) Running a selection of clustering methods (HAC or K-Means or CLARA algorithm) to group similar logbook events and defining the characteristic species-based assemblage of each cluster (DCF Level7) (Step 3).

iv) Converting them to a corresponding DCF Level5 category and comparing with simpler ordination methods (Step 4).

v) Returning a complete Eflalo dataset including the métier linked to each logbook event (Step 5).

vi) Predicting the classification of any new logbook event into the categories of defined métiers (Step 6). 



= Details =

{{{

data(eflalo)
data(correspLevel7to5)
data(correspMixedMetier)

# format
eflalo=formatEflalo(eflalo)

eflalo=eflalo[eflalo$LE_GEAR=="OTB",]
# note that output plots will be sent to getwd()
analysisName="metier_analysis_OTB"

  #-------------------------------------------------------------------------
  # I. GETTING THE DATA IN AND CLEANING FOR MISSING AND NEGATIVE VALUES ETC
  #-------------------------------------------------------------------------
  
  print("--- CREATING DIRECTORIES AND REDUCING THE EFLALO DATASET TO THE ONLY DATA NECESSARY FOR THE ANALYSIS ---")
  cat("\n") 
    
  # Creating the directory of the analysis
  if (!file.exists(analysisName)) dir.create(analysisName)
  setwd(file.path(path,analysisName))
  # Delete old R cache
  if (file.exists(".R_Cache")) unlink(".R_Cache",recursive=TRUE)                                            

  eflalo_ori = dat # Keeping this in cached memory for making the final merging at the end
  Store(eflalo_ori)

  # ! KEEPING ONLY LE_ID AND THE OUTPUT YOU WANT TO GET  (KG/EURO)
  dat=dat[,c("LE_ID",grep(critData,names(dat),value=T))]
  dat[is.na(dat)]=0

  # Removing negative and null values
  null.value <- vector()
  for (i in grep(critData,names(dat))) null.value <- c(null.value,which(dat[,i]<0))
  null.value <- c(null.value,which(apply(dat[,2:ncol(dat)],1,sum,na.rm=T)==0))

  if(length(null.value)!=0) {LogEvent.removed <- dat[sort(unique(null.value)),] ; dat <- dat[-sort(unique(null.value)),]}
  Store(LogEvent.removed)

  # Rename species names
  names(dat)[-1]=unlist(lapply(strsplit(names(dat[,-1]),"_"),function(x) x[[3]]))

  # Removing miscellaneous species
  dat <- dat[,!names(dat)=="MZZ"]
  save(dat, file="dat_cleaned.Rdata")


  #----------------------------------------------------------------------------------------------------------
  # II. EXPLORING THE VARIOUS METHODS FOR IDENTIFYING MAIN SPECIES AND KEEPING THEM IN THE DATA SET (STEP 1)
  #----------------------------------------------------------------------------------------------------------
  
  print("--- EXPLORING THE DATA FOR SELECTION OF MAIN SPECIES ---")
  cat("\n") 

  # Exploration of main species
  explo=selectMainSpecies(dat,analysisName,RunHAC=runHACinSpeciesSelection,DiagFlag=FALSE)

  # Step 1 : selection of main species
  Step1=extractTableMainSpecies(dat,explo$namesMainSpeciesHAC,paramTotal=paramTotal,paramLogevent=paramLogevent)

  save(explo,Step1,file="Explo_Step1.Rdata")
  
  
  #-----------------------------
  # III. STEP 2 - PCA - NO-PCA
  #-----------------------------

  setwd(paste(path,analysisName,sep="/"))
  if (!file.exists(critPca)) dir.create(critPca)
  setwd(file.path(path,analysisName,critPca))
  if (file.exists(".R_Cache")) unlink(".R_Cache",recursive=TRUE)

  if (critPca=="PCA_70") Step2=getTableAfterPCA(Step1,analysisName,pcaYesNo="pca",criterion="70percents") else    # criterion="70percents"
  if (critPca=="PCA_SC") Step2=getTableAfterPCA(Step1,analysisName,pcaYesNo="pca",criterion="screetest") else    # criterion="screetest"
  if (critPca=="NO_PCA") Step2=getTableAfterPCA(Step1,analysisName,pcaYesNo="nopca",criterion=NULL)

  save(Step2,file="Step2.Rdata")
  
  
  #-------------------------------------------------------
  # IV. STEP 3 - CLUSTERING METHOD : HAC, CLARA OR KMEANS
  #-------------------------------------------------------

  setwd(paste(path,analysisName,critPca,sep="/"))
  if (!file.exists(algoClust)) dir.create(algoClust)
  setwd(file.path(path,analysisName,critPca,algoClust))
  if (file.exists(".R_Cache")) unlink(".R_Cache",recursive=TRUE)

  if (algoClust=="HAC")    Step3=getMetierClusters(Step1,Step2,analysisName,methMetier="hac",param1="euclidean",param2="ward") else
  if (algoClust=="CLARA")  Step3=getMetierClusters(Step1,Step2,analysisName=analysisName,methMetier="clara",param1="euclidean",param2=NULL) else
  if (algoClust=="KMEANS") Step3=getMetierClusters(Step1,Step2,analysisName=analysisName,methMetier="kmeans",param1=NULL,param2=NULL)

  save(Step3,file="Step3.Rdata")


  #------------------------------------------------
  # V. STEP 4 - COMPARISON WITH ORDINATION METHODS
  #------------------------------------------------

  compOrdin="CompOrdin"
  setwd(paste(path,analysisName,critPca,algoClust,sep="/"))
  if (!file.exists(compOrdin)) dir.create(compOrdin)
  setwd(file.path(path,analysisName,critPca,algoClust,compOrdin))
  if (file.exists(".R_Cache")) unlink(".R_Cache",recursive=TRUE)
  
  if (algoClust=="HAC")     clusters=Step3$clusters
  if (algoClust=="CLARA")   clusters=Step3$clusters$clustering
  if (algoClust=="KMEANS")  clusters=Step3$clusters$cluster  
  
  compMetiers=compareToOrdination(dat=dat,Step2=Step2,clusters=clusters,targetSpecies=Step3$targetSpecies)
  save(compMetiers,file="compMetiers.Rdata")
  
  
  #-------------------------------------
  # VI. STEP 5 - MERGING BACK TO EFLALO
  #-------------------------------------

  # Choosing the final option
  setwd(file.path(path,analysisName))

  load(paste(path,analysisName,critPca,algoClust,"Step3.Rdata",sep="/"))

  if(!nrow(dat)==nrow(Step3$LE_ID_clust)) print("--error : number of lines in step 3 not equal to input eflalo, please check!!--")

  dat <- cbind(dat,CLUSTER=Step3$LE_ID_clust[,"clust"])

  # Now reload the full data set
  eflalo_ori[-sort(unique(null.value)),"CLUSTER"] <- Step3$LE_ID_clust[,"clust"]

  print("Congratulation !! You have now a fully working eflalo dataset with a metier Level 7 !")
  



}}}