=Benthis WP2 workflow example=

==Objectives==
  * To map habitat types and sea bed impact from fishing activities in EU waters to identify where fisheries
potentially compromises seafloor integrity and conflicts of ecosystem services
  * To develop and implement new methodology, combining VMS, logbook and industry data, to assess
actual seabed impact from large scale fishing activities on an appropriate spatial and temporal scale

==workflow==

Please find below an example workflow to treat VMS and Logbook in a systematic manner to create swept area maps.


  * Installing VMStools
    * The VMStools software is available [http://code.google.com/p/vmstools/downloads/ here]
    * The procedure for installing the VMStools library under R is described [http://code.google.com/p/vmstools/w/edit/Introduction here]
  
    * Loading the required libraries into the R console
<code>  

rm(list=ls())
library(vmstools)
library(maps)
library(mapdata)
memory.size(4000)

</code>  
  


  * setting working directories

<code>  
user <- "FRANCOIS"
if(user == "FRANCOIS"){
  codePath  <- ""
  dataPath  <- "C:/merging/EflaloAndTacsat/"
  pricePath <- ""
  outPath   <- "C:/merging/BENTHIS/outputs/"
  polPath   <- "C:/merging/BalanceMaps"
} else {
    codePath  <- "N:/Projecten/Value maps North Sea/8 Code/R/"
    dataPath  <- "R:/tacsatEflalo/"
    pricePath <- "N:/Projecten/Value maps North Sea/8 Code/Data/"
    outPath   <- "N:/Projecten/Value maps North Sea/8 Code/Results/"
    polPath   <- "D:/Repository/VMStools/polygons/"
  }
if(substr(R.Version()$os,1,3)== "lin"){
  codePath  <- sub("N:/","/media/n/",codePath)
  dataPath  <- sub("N:/","/media/n/",dataPath)
  outPath   <- sub("N:/","/media/n/",outPath)
  polPath   <- sub("N:/","/media/n/",polPath)
}
     
# some global variables
spThres   <- 20   #Maximum speed threshold in analyses in nm
intThres  <- 5    #Minimum difference in time interval in minutes to prevent pseudo duplicates
lanThres  <- 1.5  #Maximum difference in log10-transformed sorted weights
spatBound <- list(xrange = c(-4,10),yrange = c(50,62))
year      <- 2011
</code>  

  * loading VMS and Logbook data
 
<code>  
 load(file.path(dataPath,"tacsat_2011.RData")); tacsat <- tacsat
 load(file.path(dataPath,"eflalo_2011.RData")); eflalo <- eflalo
</code>  

We assume that the fishing activities/metier (LE_MET) are fully informed in the eflalo data
 
  * load vmstools underlying data
<code>  
  data(euharbours)
  data(ICESareas)
  data(europa)
</code>  

  * have a look at e.g. harbours e.g. using ggmap

<code>  
  coord.ports <- harbours
  require(ggmap)
  require(mapproj)
  map.center <- geocode("copenhaguen")
  SHmap <- qmap(c(lon=map.center$lon, lat=map.center$lat), maprange = TRUE, source="google", zoom=7)
  
  coord.ports$lon <- as.numeric(as.character(coord.ports$lon ))
  coord.ports$lat <- as.numeric(as.character(coord.ports$lat ))
  
  SHmap + geom_point(
  aes(x=lon, y=lat, colour= "black"), data=coord.ports) +
  scale_colour_manual(values=c("1"="dark blue","2"="orange"))
  savePlot(filename=file.path(outPath,
       paste("ggmap_ports.jpeg",sep='')), type="jpeg")
</code>  


  * cleaning tacsat

<code>  
  #-------------------------------------------------------------------------------
  #- Keep track of removed points
  #-------------------------------------------------------------------------------
  remrecsTacsat     <- matrix(NA,nrow=6,ncol=2,dimnames= list(c("total","duplicates","notPossible","pseudoDuplicates","harbour","land"),c("rows","percentage")))
  remrecsTacsat["total",] <- c(nrow(tacsat),"100%")

  #-------------------------------------------------------------------------------
  #- Remove duplicate records
  #-------------------------------------------------------------------------------
  tacsat$SI_DATIM <- as.POSIXct(paste(tacsat$SI_DATE,  tacsat$SI_TIME,   sep=" "), tz="GMT", format="%d/%m/%Y  %H:%M")
  uniqueTacsat    <- paste(tacsat$VE_REF,tacsat$SI_LATI,tacsat$SI_LONG,tacsat$SI_DATIM)
  tacsat          <- tacsat[!duplicated(uniqueTacsat),]
  remrecsTacsat["duplicates",] <- c(nrow(tacsat),100+round((nrow(tacsat) - an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Remove points that cannot be possible
  #-------------------------------------------------------------------------------
  idx             <- which(abs(tacsat$SI_LATI) > 90 | abs(tacsat$SI_LONG) > 180)
  idx             <- unique(c(idx,which(tacsat$SI_HE < 0 | tacsat$SI_HE > 360)))
  idx             <- unique(c(idx,which(tacsat$SI_SP > spThres)))
  if(length(idx)>0) tacsat          <- tacsat[-idx,]
  remrecsTacsat["notPossible",] <- c(nrow(tacsat),100+round((nrow(tacsat) - an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Remove points which are pseudo duplicates as they have an interval rate < x minutes
  #-------------------------------------------------------------------------------
  tacsat          <- sortTacsat(tacsat)
  tacsatp         <- intervalTacsat(tacsat,level="vessel",fill.na=T)
  tacsat          <- tacsatp[which(tacsatp$INTV > intThres | is.na(tacsatp$INTV)==T),-grep("INTV",colnames(tacsatp))]
  remrecsTacsat["pseudoDuplicates",] <- c(nrow(tacsat),100+round((nrow(tacsat) - an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Remove points in harbour
  #-------------------------------------------------------------------------------
  idx             <- pointInHarbour(tacsat$SI_LONG,tacsat$SI_LATI,harbours); pih <- tacsat[which(idx == 1),]
  save(pih,file=paste(outPath,"pointInHarbour.RData",sep=""))
  tacsat          <- tacsat[which(idx == 0),]
  remrecsTacsat["harbour",] <- c(nrow(tacsat),100+round((nrow(tacsat) - an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Remove points on land
  #-------------------------------------------------------------------------------
  pols            <- lonLat2SpatialPolygons(lst=lapply(as.list(sort(unique(europa$SID))),
                        function(x){data.frame(SI_LONG=subset(europa,SID==x)$X,SI_LATI=subset(europa,SID==x)$Y)}))
  idx             <- pointOnLand(tacsat,pols); pol <- tacsat[which(idx == 1),]
  save(pol,file=paste(outPath,"pointOnLand.RData",sep=""))
  tacsat          <- tacsat[which(idx == 0),]
  remrecsTacsat["land",] <- c(nrow(tacsat),100+round((nrow(tacsat) - an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Save the remrecsTacsat file
  #-------------------------------------------------------------------------------
  save(remrecsTacsat,file=file.path(outPath,"remrecsTacsat.RData"))

  #-------------------------------------------------------------------------------
  #- Save the cleaned tacsat file
  #-------------------------------------------------------------------------------
  save(tacsat,file=file.path(outPath,"cleanTacsat.RData"))
  </code>  

 
 
 
  * cleaning eflalo

<code>
  #-------------------------------------------------------------------------------
  #- Keep track of removed points
  #-------------------------------------------------------------------------------
  remrecsEflalo     <- matrix(NA,nrow=5,ncol=2,dimnames=list(c("total","duplicated","impossible time","before 1st Jan","departArrival"),c("rows","percentage")))
  remrecsEflalo["total",] <- c(nrow(eflalo),"100%")

  #-------------------------------------------------------------------------------
  #- Remove non-unique trip numbers
  #-------------------------------------------------------------------------------
  eflalo <- eflalo[!duplicated(paste(eflalo$LE_ID,eflalo$LE_CDAT,sep="-")),]
  remrecsEflalo["duplicated",] <- c(nrow(eflalo),100+round((nrow(eflalo) - an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
  
  #-------------------------------------------------------------------------------
  #- Remove impossible time stamp records
  #-------------------------------------------------------------------------------
  
  eflalo$FT_DDATIM <- as.POSIXct(paste(eflalo$FT_DDAT,eflalo$FT_DTIME, sep = " "), tz = "GMT", format = "%d/%m/%Y  %H:%M")
  eflalo$FT_LDATIM <- as.POSIXct(paste(eflalo$FT_LDAT,eflalo$FT_LTIME, sep = " "), tz = "GMT", format = "%d/%m/%Y  %H:%M")

  eflalo <- eflalo[!(is.na(eflalo$FT_DDATIM) |is.na(eflalo$FT_LDATIM)),] 
  remrecsEflalo["impossible time",] <- c(nrow(eflalo),100+round((nrow(eflalo) - an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))

  #-------------------------------------------------------------------------------
  #- Remove trip starting befor 1st Jan
  #-------------------------------------------------------------------------------
  eflalo <- eflalo[eflalo$FT_DDATIM>=strptime(paste(year,"-01-01 00:00:00",sep=''),"%Y-%m-%d %H:%M:%S"),]
  remrecsEflalo["before 1st Jan",] <- c(nrow(eflalo),100+round((nrow(eflalo) - an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
                                                                                                                                                                                                                                
  #-------------------------------------------------------------------------------
  #- Remove records with arrival date before departure date
  #-------------------------------------------------------------------------------
  eflalop           <- eflalo
  eflalop$FT_DDATIM <- as.POSIXct(paste(eflalo$FT_DDAT,  eflalo$FT_DTIME,   sep=" "), tz="GMT", format="%d/%m/%Y  %H:%M")
  eflalop$FT_LDATIM <- as.POSIXct(paste(eflalo$FT_LDAT,  eflalo$FT_LTIME,   sep=" "), tz="GMT", format="%d/%m/%Y  %H:%M")
  idx               <- which(eflalop$FT_LDATIM >= eflalop$FT_DDATIM)
  eflalo            <- eflalo[idx,]
  remrecsEflalo["departArrival",] <- c(nrow(eflalo),100+round((nrow(eflalo) - an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
 
  #-------------------------------------------------------------------------------
  #- Save the remrecsEflalo file
  #-------------------------------------------------------------------------------
  save(remrecsEflalo,file=file.path(outPath,"remrecsEflalo.RData"))  

  #-------------------------------------------------------------------------------
  #- Save the cleaned eflalo file
  #-------------------------------------------------------------------------------
  save(eflalo,file=file.path(outPath,"cleanEflalo.RData"))
</code>  






  * merge eflalo and tacsat

<code>  
  tacsatp           <- mergeEflalo2Tacsat(eflalo,tacsat)
</code>  










  * link gear characteristics to tacsat 

<code>  
  tacsatp$LE_GEAR   <- eflalo$LE_GEAR[match(tacsatp$FT_REF,eflalo$FT_REF)]
  tacsatp$VE_LEN    <- eflalo$VE_LEN[ match(tacsatp$FT_REF,eflalo$FT_REF)]
  tacsatp$LE_MET    <- eflalo$LE_MET[ match(tacsatp$FT_REF,eflalo$FT_REF)]
  save(tacsatp,   file=paste(outPath,"tacsatMerged.RData",   sep=""))
  head(tacsatp[is.na(tacsatp$LE_GEAR),]) 
   # =>check for some cases with no match!
</code>  






  * read in look-up table (industry data from interviews / experimental studies) making use 
of functional relationship between vessel HP or length to gear size

<code>  
  # create a fake input file to show the required format
  #dd <- tacsatp[!duplicated(data.frame(tacsatp$VE_REF,tacsatp$LE_GEAR)), ] 
  #fake_gear_width_table <- dd[,c('VE_REF', 'LE_GEAR')]
  #fake_gear_width_table$LE_GEAR_WIDTH <- 0.5 # in km
  # gear_width_table <- fake_gear_width_table  
  #save(gear_width_table,   file=paste(dataPath,"gear_width_vid_gr.RData",   sep=""))
  
  load(file.path(dataPath, "gear_width_vid_gr.RData"))
  tacsatp <- merge(tacsatp, gear_width_table) 
    
  # save 
  save(tacsatp,   file=paste(outPath,"tacsatMergedWidth.RData",   sep=""))
</code>  










  * Save not merged tacsat data
<code>  
  tacsatpmin        <- subset(tacsatp,FT_REF == 0)
  save(tacsatpmin,file=paste(outPath,"tacsatNotMerged.RData",sep=""))
</code>  






  * define activity depending on speed profiles

<code>  
  #-------------------------------------------------------------------------------
  #- Remove points with NA's in them in critial places
  #-------------------------------------------------------------------------------
  idx             <- which(is.na(tacsatp$VE_REF) == T   | is.na(tacsatp$SI_LONG) == T | is.na(tacsatp$SI_LATI) == T |
                           is.na(tacsatp$SI_DATIM) == T |  is.na(tacsatp$SI_SP) == T)
  if(length(idx)>0) tacsatp         <- tacsatp[-idx,]

  #-------------------------------------------------------------------------------
  #- Analyse activity (semi-)automated
  #-------------------------------------------------------------------------------
  storeScheme     <- activityTacsatAnalyse(tacsatp, units = "year", analyse.by = "LE_GEAR",identify="means") # use 5 peaks for all gears only!!
  storeScheme     <- storeScheme[-which(is.na(storeScheme$analyse.by)==T),]
  save(storeScheme,file=paste(outPath,"storeScheme.RData",sep=""))

  #  cat("Note that in case of 5 peaks: no fishing = 1, fishing = 2, steaming / no fishing = 3\n")
  #  cat("Note that in case of 3 peaks: fishing = 1, steaming / no fishing = 2\n")

  storeScheme       <- storeScheme[storeScheme$years==year,]    # debug added fba
  storeScheme$years <- as.numeric(as.character(storeScheme$years))  # debug added fba
  tacsatp$year      <- format(tacsatp$SI_DATIM, "%Y") # debug added fba
  tacsatp           <- tacsatp[tacsatp$year %in% year,] # debug added fba

 
  activity          <- activityTacsat(tacsatp,units="year",analyse.by="LE_GEAR",storeScheme,
                                  plot=TRUE,level="all",sigma=1)
  tacsatp$SI_STATE  <- NA
  tacsatp$SI_STATE  <- activity


  #-------------------------------------------------------------------------------
  #- Assign for the remaining (NA) points a simple speed rule classification
  #-------------------------------------------------------------------------------
  idx             <- which(is.na(tacsatp$SI_STATE))
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] >= 1.5 & tacsatp$SI_SP[idx] <= 7.5)]] <- 2
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] < 1.5)]]                              <- 1
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] > 7.5)]]                              <- 3

  #-------------------------------------------------------------------------------
  #- Save the analysed scheme and defined activity tacsat file
  #-------------------------------------------------------------------------------
  save(storeScheme, file=file.path(outPath,"storeScheme.RData"))
  save(tacsatp,     file=file.path(outPath,"tacsatActivity.RData"))
</code>  


<code>  
</code>  

  * need for Fock??

<code>  
</code>  

  * interpolate data

<code>  
</code>  

  * interpolate the tracks between VMS fishing positions for active towed gears (excluding seiners)
   i.e. OTB, TBB, PTB, PTM and DRB using interpolateTacsat() 
   and convert back to the tacsat format using interpolation2Tacsat(). 
   The swept area is assigned to each ping.
 

<code>  
  load(file=paste(outPath,"tacsatActivity.RData",   sep="")) # get tacsatp
      #=> SI_STATE 1: slow motion; SI_STATE 2: fishing; SI_STATE 3: steaming 

  towed_gears <- c('OTB', 'TBB', 'PTB', 'PTM', 'DRB')
  
  # order chronologically (if not done yet)
  tacsatp           <- orderBy(~VE_REF+SI_DATIM,data=tacsatp)  
   
  # frame each haul by two steaming positions
  is_transition  <- c(0,diff(tacsatp$SI_STATE))
  is_transition2 <- c(diff(tacsatp$SI_STATE), 0)
  tacsatp <- tacsatp[ !is.na(tacsatp$SI_STATE) & (tacsatp$SI_STATE ==2 | is_transition!=0 | is_transition2!=0),] 
   
  # create an output folder for storing files 
  dir.create(file.path(outPath, "interpolated"))
   
  # apply per gear per vessel (otherwise risk for 'out of memory')
    for(gr in towed_gears){
      tacsatp_gr        <- tacsatp[!is.na(tacsatp$LE_GEAR) & tacsatp$LE_GEAR==gr,]
      tacsatp_gr$VE_REF <- factor(tacsatp_gr$VE_REF)
   
      for(vid in levels(tacsatp_gr$VE_REF)){
          cat(paste("apply on ", vid, " and ", gr, "\n", sep=""))
  
          tacsatp_gr_vid <- tacsatp_gr[tacsatp_gr$VE_REF %in% vid,]
          if(nrow(tacsatp_gr_vid)>3) {
 
          #Interpolate according to the cubic-hermite spline interpolation
          interpolationcHs <- interpolateTacsat(tacsatp_gr_vid,
                            interval=60,
                            margin=10, # i.e. will make disconnected interpolations if interval out of the 50 70min range
                            res=100,
                            method="cHs",
                            params=list(fm=0.2,distscale=20,sigline=0.2,st=c(2,6)),   # rmenber that st not in use....
                            headingAdjustment=0,
                            fast=FALSE)

          #Make a picture of all interpolations first
          #Get the ranges of the total picture
          #ranges <- do.call(rbind,lapply(cHs,function(x){return(apply(x[-1,],2,range))}))
          #xrange <- range(ranges[,"x"])
          #yrange <- range(ranges[,"y"])
 
          #plot(tacsatp_gr_vid$SI_LONG, tacsatp_gr_vid$SI_LATI, 
          #       xlim=xrange,ylim=yrange,pch=19,col="blue",xlab="Longitude",ylab="Latitude")
          #for(iInt in 1:length(cHs)){
          #lines(cHs[[iInt]][-1,1],cHs[[iInt]][-1,2])}

              
          #Convert the interpolation to tacsat style data
          tacsatp_gr_vid$SI_TIME <- as.character(tacsatp_gr_vid$SI_TIME) # debug fba
          tacsatInt_gr_vid       <- interpolation2Tacsat(interpolationEQ, tacsatp_gr_vid) 
          # => note that equalDistance() is encapsulated in interpolation2Tacsat()
          # Each interpolation is splitted into 10 equally spaced points (including the start and the end point). 
          # In total 8 new points are added per interpolation.
          
                                
          # visual check
          plot(tacsatInt_gr_vid$SI_LONG, tacsatInt_gr_vid$SI_LATI, pch=".", col=2)
          points(tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE!=2,'SI_LONG'], 
                       tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE!=2,'SI_LATI'], col=3, pch=16) # steaming (remaining ones (because we are conservative here))
          points(tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE==2,'SI_LONG'], 
                       tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE==2,'SI_LATI'], col=2, pch=16) # fishnig

  
        # What is the distance traveled within each of these interpolations?
        sum(distanceInterpolation(interpolationcHs))

        #compute the swept area from the distance and the gear width
        #.......
        # tacsatp_gr_vid$SWEPT_AREA_KM2 <- distance()*width
          
       
       # save (a file by gr_vid)
       save(tacsatInt_gr_vid, file=file.path(outPath, "interpolated", 
           paste("tacsatFishSeqInterpolAndWidth_",vid, "_", gr, ".RData", sep="")))
     } # end if enough records
    } # end vid
  } # end gr
 
 
 </code>  









  * buffer area (passive gear)

<code>  
all_gears      <- levels(tacsatp$LE_GEAR)
passive_gears  <- all_gears[!all_gears %in% towed_gears]
# TO DO.......
</code>  










  * bound all the files to one
  
<code>  
   # after having subsetted per gear per vessel (because risk of 'out of memory')
    lst <- list(NULL) ; count <- 0
    for(gr in levels(tacsatp$LE_GEAR)){
      tacsatp_gr        <- tacsatp[!is.na(tacsatp$LE_GEAR) & tacsatp$LE_GEAR==gr,]
      tacsatp_gr$VE_REF <- factor(tacsatp_gr$VE_REF)
   
      for(vid in levels(tacsatp_gr$VE_REF)){
          count <- count+1
        
          cat(paste("load ", vid, " and ", gr, "\n", sep=""))
          er <- try(load(file.path(outPath, "interpolated", 
                paste("tacsatFishSeqInterpolAndWidth_", vid, "_", gr, ".RData", sep=""))),
                silent=TRUE)
          if(class(er)=="try-error"){
          count <- count -1
          } else{      
          lst[[count]] <-  tacsatInt_gr_vid
          }
     
      }
      
    }
    tacsatp <- do.call("rbind", lst) 
</code>  






  * labelling each haul  

<code>  
# assign an identifier in'HL_ID' to each of the fishing sequences
# (useful to count them in a grid...)
labelHauls <- function(tacsat){
            tacsat[is.na(tacsat$SI_STATE), 'SI_STATE'] <- 1 # assign steaming
            tacsat[tacsat$SI_STATE!=2, 'SI_STATE']     <- 1 # assign steaming
            tacsat$HL_ID                              <- c(0, diff(tacsat$SI_STATE))   # init
            tacsat$HL_ID                              <- cumsum(tacsat$HL_ID) # fishing sequences detected.
            tacsat$HL_ID                              <- 1- tacsat$HL_ID  # steaming sequences detected.
            tacsat$HL_ID                              <- cumsum(tacsat$SS_ID ) # fishing sequences labelled.
            tacsat[tacsat$SI_STATE==1, 'HL_ID']       <- 0 # correct label 0 for steaming
            tacsat$HL_ID                              <- factor(tacsat$HL_ID)
            levels(tacsat$FS_REF) <- 0: (length(levels(tacsat$FS_REF))-1) # rename the id for increasing numbers from 0
            tacsat$HL_ID                             <- as.character(tacsat$HL_ID)
            # then assign a unique id
            idx <- tacsat$FS_REF!=0
            tacsat[idx, "HL_ID"] <- paste(
                                    tacsat$VE_REF[idx], "_", 
                                    tacsat$LE_GEAR[idx], "_", 
                                    tacsat$HL_ID[idx],
                                    sep="")
          tacsat <- tacsat[, !colnames(tacsat) %in% 'SS_ID'] # remove useless column
          return(tacsat)
       }  

# label fishing sequecnes with a unique identifier (method based on SI_STATE) 
tacsat <- labelHauls(tacsat)  
   
 



</code>  



  * severity of activity: read a look-up table (from interviews / experimental studies)


<code>  
</code>  






  * link habitat map to vms


    * shapefile 

<code>  
</code>  

    * raster

<code>  
</code>  







  * define grid
    * mid-point polygon distance distribution

<code>  
</code>  






    * random process of fishing activity

<code>  
</code>  






  * maps + sum / average different grids

<code>  
</code>  





  * non-vms maps

<code>  
</code>  





  * testing

<code>  
</code>  