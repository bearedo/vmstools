=Benthis WP2 workflow example=

Welcome to the Benthis workflow example wiki. The page is hosted on the VMStools page
as for this analyses you will be required to install the VMStools software for R.
Please note that at this stage (May 2013), VMStools will only operate on R-2.15.x versions.

==Objectives==
  * To map habitat types and sea bed impact from fishing activities in EU waters to identify where fisheries potentially compromises seafloor integrity and conflicts of ecosystem services
  * To develop and implement new methodology, combining VMS, logbook and industry data, to assess actual seabed impact from large scale fishing activities on an appropriate spatial and temporal scale

==workflow==

Please find below an example workflow to treat VMS and Logbook in a systematic manner to create swept area maps.


=== Installing VMStools ===
  * The VMStools software is available [http://code.google.com/p/vmstools/downloads/list here]
  * The procedure for installing the VMStools library under R is described [http://code.google.com/p/vmstools/wiki/Introduction?tm=6 here]
  
=== Loading the required libraries into the R console ===
We load three different libraries, to start with the VMStools one, followed by two packages that help us to create maps. If you have not installed them, please use {{{install.packages("maps",repos=getOption("repos")}}} and select the correct packages.
<code>  
rm(list=ls())
library(vmstools)
library(maps)
library(mapdata)
memory.size(4000)
</code>  
  
In general, workflows can be easily adapted to each users' computer by setting working directories first. You may need to adjust these to direct to the <br> folders you would like to store the results in.

=== setting working directories ===

<code>  
codePath  <- "D:/Benthis/Code/R/"
dataPath  <- "D:/Benthis/Data/"
pricePath <- "D:/Benthis/Data/Price/"
outPath   <- "D:/Benthis/Output/"
polPath   <- "D:/Benthis/Data/Polygons/"
</code>

=== loading VMS and Logbook data ===
 
The VMS data we use in this analyses must be formatted to the 'tacsat' style. The logbook data must be formatted in the 'eflalo' style. You can download a description of these formats [http://code.google.com/p/vmstools/downloads/list here] and if you want another example, in the VMStools package an example tacsat and eflalo dataset are embedded. Load the VMStools library and call these by typing {{{data(tacsat)}}} or {{{data(eflalo)}}}.
If you have the data in R format already, you can read them in as below.
<code>  
load(file.path(dataPath,"tacsat.RData")); # get the tacsat object
load(file.path(dataPath,"eflalo.RData")); # get the eflalo object
</code>  

If they are in a .csv format, you could use the following lines.

<code>
tacsat <- readTacsat(file.path(dataPath,"tacsat.csv"))
eflalo <- readEflalo(file.path(dataPath,"eflalo.csv"))
</code>

Make sure that the fishing activities / metier (the 'LE_MET' column in eflalo) is present and complete.
 
=== load VMStools additional datasets ===
<code>  
data(euharbours)
data(ICESareas)
data(europa)
</code>  

Let's take a look at e.g. the ICES areas and harbours dataset.

<code>  
map("worldHires",xlim=c(-15,15),ylim=c(40,65),fill=T,col="#7FBC41",oma=rep(0,4),mar=rep(2.5,4))
plot(ICESareas,add=T,col="lightblue")
points(harbours$lon,harbours$lat,pch=16,col="blue",cex=0.4)
map.axes()
</code>  
It should look something like this:<br>
[http://vmstools.googlecode.com/svn/wiki/figures/harbours.png]


=== Cleaning the tacsat dataset ===
In general, the tacsat dataset contains many errors, such as duplicates, points that are on land or not even on the globe. These need to be filtered out before we execute the analyses. Most of these 'problems' have been identified by different authors of peer-reviewed papers, and we treat the most common ones below.

  
  * It is a good idea to keep track of those records you have removed 
<code>
remrecsTacsat     <- matrix(NA,nrow=6,ncol=2,dimnames= list(c("total","duplicates","notPossible",
                                                              "pseudoDuplicates","harbour","land"),
                                                            c("rows","percentage")))
remrecsTacsat["total",] <- c(nrow(tacsat),"100%")
</code>

  * Remove duplicate records 
<code>
tacsat$SI_DATIM <- as.POSIXct(paste(tacsat$SI_DATE,  tacsat$SI_TIME,   sep=" "),
                              tz="GMT", format="%d/%m/%Y  %H:%M")
uniqueTacsat    <- paste(tacsat$VE_REF,tacsat$SI_LATI,tacsat$SI_LONG,tacsat$SI_DATIM)
tacsat          <- tacsat[!duplicated(uniqueTacsat),]
remrecsTacsat["duplicates",] <- c(nrow(tacsat),100+round((nrow(tacsat) -
                an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))
</code>

  * Remove points that cannot be possible
<code>
spThres         <- 20   #Maximum speed threshold in analyses in nm
  idx           <- which(abs(tacsat$SI_LATI) > 90 | abs(tacsat$SI_LONG) > 180)
  idx           <- unique(c(idx,which(tacsat$SI_HE < 0 | tacsat$SI_HE > 360)))
  idx           <- unique(c(idx,which(tacsat$SI_SP > spThres)))
if(length(idx)>0) tacsat          <- tacsat[-idx,]
remrecsTacsat["notPossible",] <- c(nrow(tacsat),100+round((nrow(tacsat) -
                an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))
</code>

  * Remove points which are pseudo duplicates as they have an interval rate < x minutes
<code>
intThres        <- 5    # Minimum difference in time interval in minutes to prevent pseudo duplicates
tacsat          <- sortTacsat(tacsat)
tacsatp         <- intervalTacsat(tacsat,level="vessel",fill.na=T)
tacsat          <- tacsatp[which(tacsatp$INTV > intThres | is.na(tacsatp$INTV)==T),-grep("INTV",colnames(tacsatp))]
remrecsTacsat["pseudoDuplicates",] <- c(nrow(tacsat),100+round((nrow(tacsat) -
                an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))
</code>

  * Remove points in harbour
<code>
idx             <- pointInHarbour(tacsat$SI_LONG,tacsat$SI_LATI,harbours)
pih             <- tacsat[which(idx == 1),]
save(pih,file=paste(outPath,"pointInHarbour.RData",sep=""))
tacsat          <- tacsat[which(idx == 0),]
remrecsTacsat["harbour",] <- c(nrow(tacsat),100+round((nrow(tacsat) -
                an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))
</code>

  * Remove points on land
<code>
pols            <- lonLat2SpatialPolygons(lst=lapply(as.list(sort(unique(europa$SID))),
                        function(x){data.frame(SI_LONG=subset(europa,SID==x)$X,SI_LATI=subset(europa,SID==x)$Y)}))
idx             <- pointOnLand(tacsat,pols); pol <- tacsat[which(idx == 1),]
save(pol,file=paste(outPath,"pointOnLand.RData",sep=""))
tacsat          <- tacsat[which(idx == 0),]
remrecsTacsat["land",] <- c(nrow(tacsat),100+round((nrow(tacsat) -
                an(remrecsTacsat["total",1]))/an(remrecsTacsat["total",1])*100,2))
</code>

  * Save the remrecsTacsat file
<code>
save(remrecsTacsat,file=file.path(outPath,"remrecsTacsat.RData"))
</code>
The result, based on the VMStools tacsat dataset, looks like:
|| *Category* || *Records left* || *Percentage of original* ||
|| total || 97015 || 100% ||
|| duplicates || 97015 || 100% ||
|| not possible || 97001 || 99.99% ||
|| pseudo duplicates || 84774 || 87.38% ||
|| in harbour || 70948 || 73.13% ||
|| on land || 70063 || 72.22% ||

  * Save the cleaned tacsat file
<code>
save(tacsat,file=file.path(outPath,"cleanTacsat.RData"))
</code>  

 
=== cleaning eflalo ===
Very similar to cleaning the tacsat dataset, we need to clean the eflalo dataset too.

  * Keep track of removed points
<code>
remrecsEflalo     <- matrix(NA,nrow=5,ncol=2,dimnames=list(c("total","duplicated","impossible time",
                                                             "before 1st Jan","departArrival"),
                                                           c("rows","percentage")))
remrecsEflalo["total",] <- c(nrow(eflalo),"100%")
</code>

  * Remove non-unique trip numbers
<code>
eflalo            <- eflalo[!duplicated(paste(eflalo$LE_ID,eflalo$LE_CDAT,sep="-")),]
remrecsEflalo["duplicated",] <- c(nrow(eflalo),100+round((nrow(eflalo) -
                  an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
</code>

  * Remove impossible time stamp records
<code>
  eflalo$FT_DDATIM <- as.POSIXct(paste(eflalo$FT_DDAT,eflalo$FT_DTIME, sep = " "),
                                 tz = "GMT", format = "%d/%m/%Y  %H:%M")
  eflalo$FT_LDATIM <- as.POSIXct(paste(eflalo$FT_LDAT,eflalo$FT_LTIME, sep = " "),
                                 tz = "GMT", format = "%d/%m/%Y  %H:%M")

  eflalo <- eflalo[!(is.na(eflalo$FT_DDATIM) |is.na(eflalo$FT_LDATIM)),] 
  remrecsEflalo["impossible time",] <- c(nrow(eflalo),100+round((nrow(eflalo) -
                  an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
</code>
  
  * Remove trip starting befor 1st Jan
<code>
year              <- min(year(eflalo$FT_DDATIM))
eflalo            <- eflalo[eflalo$FT_DDATIM>=strptime(paste(year,"-01-01 00:00:00",sep=''),
                                                             "%Y-%m-%d %H:%M:%S"),]
remrecsEflalo["before 1st Jan",] <- c(nrow(eflalo),100+round((nrow(eflalo) -
                  an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
</code>

  * Remove records with arrival date before departure date
<code>
eflalop           <- eflalo
eflalop$FT_DDATIM <- as.POSIXct(paste(eflalo$FT_DDAT,  eflalo$FT_DTIME,   sep=" "),
                                tz="GMT", format="%d/%m/%Y  %H:%M")
eflalop$FT_LDATIM <- as.POSIXct(paste(eflalo$FT_LDAT,  eflalo$FT_LTIME,   sep=" "),
                                tz="GMT", format="%d/%m/%Y  %H:%M")
idx               <- which(eflalop$FT_LDATIM >= eflalop$FT_DDATIM)
eflalo            <- eflalo[idx,]
remrecsEflalo["departArrival",] <- c(nrow(eflalo),100+round((nrow(eflalo) -
                  an(remrecsEflalo["total",1]))/an(remrecsEflalo["total",1])*100,2))
</code>

  * Save the remrecsEflalo file
<code>
save(remrecsEflalo,file=file.path(outPath,"remrecsEflalo.RData"))
</code>

The result, based on the VMStools eflalo dataset, looks like:
|| *Category* || *Records left* || *Percentage of original* ||
|| total || 4539 || 100% ||
|| duplicated || 4446 || 97.95% ||
|| impossible time || 4446 || 97.95% ||
|| before 1st of Jan || 4446 || 97.95% ||
|| departure before arrival || 4446 || 97.95% ||

  * Save the cleaned eflalo file
<code>
save(eflalo,file=file.path(outPath,"cleanEflalo.RData"))
</code>  






  * merge eflalo and tacsat

<code>  
  tacsatp           <- mergeEflalo2Tacsat(eflalo,tacsat)
</code>  










  * link gear characteristics to tacsat 

<code>  
  tacsatp$LE_GEAR   <- eflalo$LE_GEAR[match(tacsatp$FT_REF,eflalo$FT_REF)]
  tacsatp$VE_LEN    <- eflalo$VE_LEN[ match(tacsatp$FT_REF,eflalo$FT_REF)]
  tacsatp$LE_MET    <- eflalo$LE_MET[ match(tacsatp$FT_REF,eflalo$FT_REF)]
  save(tacsatp,   file=paste(outPath,"tacsatMerged.RData",   sep=""))
  head(tacsatp[is.na(tacsatp$LE_GEAR),]) 
   # =>check for some cases with no match!
</code>  






  * read in look-up table (industry data from interviews / experimental studies) making use 
of functional relationships between vessel HP or length to gear size. The gear width for a trawl is straightforward.
The gear width for a seine should be the length of the net. The gear width of a gillnets or other should be
the nb of nets released per operation times the unit net length. This need to be confirmed by the industry.

<code>  
  # create a fake input file to show the required format
  #dd <- tacsatp[!duplicated(data.frame(tacsatp$VE_REF,tacsatp$LE_GEAR)), ] 
  #fake_gear_width_table <- dd[,c('VE_REF', 'LE_GEAR')]
  #fake_gear_width_table$LE_GEAR_WIDTH <- 0.5 # in km
  # gear_width_table <- fake_gear_width_table  
  #save(gear_width_table,   file=paste(dataPath,"gear_width_vid_gr.RData",   sep=""))
  
  load(file.path(dataPath, "gear_width_vid_gr.RData"))
  tacsatp <- merge(tacsatp, gear_width_table) 
    
  # save 
  save(tacsatp,   file=paste(outPath,"tacsatMergedWidth.RData",   sep=""))
</code>  










  * Save not merged tacsat data
<code>  
  tacsatpmin        <- subset(tacsatp,FT_REF == 0)
  save(tacsatpmin, file=paste(outPath,"tacsatNotMerged.RData",sep=""))
</code>  






  * define activity depending on speed profiles.
    This step identifies the fishing activities from the steaming phases by analysing the vessel-specific speed profile and knowing the type of gear used from the logbooks.


<code>  
  #-------------------------------------------------------------------------------
  #- Remove points with NA's in them in critial places
  #-------------------------------------------------------------------------------
  idx             <- which(is.na(tacsatp$VE_REF) == T   | is.na(tacsatp$SI_LONG) == T | is.na(tacsatp$SI_LATI) == T |
                           is.na(tacsatp$SI_DATIM) == T |  is.na(tacsatp$SI_SP) == T)
  if(length(idx)>0) tacsatp         <- tacsatp[-idx,]

  #-------------------------------------------------------------------------------
  #- Analyse activity (semi-)automated
  #-------------------------------------------------------------------------------
  storeScheme     <- activityTacsatAnalyse(tacsatp, units = "year", analyse.by = "LE_GEAR",identify="means") # use 3 or 5 peaks 
  storeScheme     <- storeScheme[-which(is.na(storeScheme$analyse.by)==T),]
  save(storeScheme, file=paste(outPath,"storeScheme.RData",sep=""))

  storeScheme       <- storeScheme[storeScheme$years==year,]    # debug added fba
  storeScheme$years <- as.numeric(as.character(storeScheme$years))  # debug added fba
  tacsatp$year      <- format(tacsatp$SI_DATIM, "%Y") # debug added fba
  tacsatp           <- tacsatp[tacsatp$year %in% year,] # debug added fba

 
  activity          <- activityTacsat(tacsatp,units="year",analyse.by="LE_GEAR",storeScheme,
                                  plot=TRUE,level="all",sigma=1)
  tacsatp$SI_STATE  <- NA
  tacsatp$SI_STATE  <- activity


  #-------------------------------------------------------------------------------
  #- Assign for the remaining (NA) points a simple speed rule classification
  #-------------------------------------------------------------------------------
  idx             <- which(is.na(tacsatp$SI_STATE))
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] >= 1.5 & tacsatp$SI_SP[idx] <= 7.5)]] <- 'f'
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] < 1.5)]]                              <- 'h'
  tacsatp$SI_STATE[idx[which(tacsatp$SI_SP[idx] > 7.5)]]                              <- 's'

  #-------------------------------------------------------------------------------
  #- Save the analysed scheme and defined activity tacsat file
  #-------------------------------------------------------------------------------
  save(storeScheme, file=file.path(outPath,"storeScheme.RData"))
  save(tacsatp,     file=file.path(outPath,"tacsatActivity.RData"))
</code>  


<code>  
</code>  

  * need for Fock??

<code>  
</code>  

  * interpolate data (or not) and compute the swept area


   - interpolate the tracks between VMS fishing positions for active towed gears (excluding seiners)
   i.e. OTB, TBB, PTB, PTM and DRB using interpolateTacsat() 
   and convert back to the tacsat format using interpolation2Tacsat(). 
   The swept area is assigned to each ping.
 

<code>  
  load(file=paste(outPath,"tacsatActivity.RData",   sep="")) # get tacsatp
      #=> SI_STATE "h": slow motion/handling; SI_STATE "f": fishing; SI_STATE "s": steaming 

  towed_gears <- c('OTB', 'TBB', 'PTB', 'PTM', 'DRB')  # TO DO: list to be checked
  
  # order chronologically (if not done yet)
  tacsatp           <- orderBy(~VE_REF+SI_DATIM,data=tacsatp)  
   
  # you might frame each haul by two steaming positions to be conservative
  tacsatp$SI_STATE_num <- NA
  tacsatp[tacsatp$SI_STATE=="h","SI_STATE_num"] <- 1 
  tacsatp[tacsatp$SI_STATE=="f","SI_STATE_num"] <- 2 
  tacsatp[tacsatp$SI_STATE=="s","SI_STATE_num"] <- 3 
  is_transition  <- c(0,diff(tacsatp$SI_STATE_num))
  is_transition2 <- c(diff(tacsatp$SI_STATE_num), 0)
  tacsatp <- tacsatp[ !is.na(tacsatp$SI_STATE_num) & (tacsatp$SI_STATE_num ==2 | is_transition!=0 | is_transition2!=0),] 
   
  # create an output folder for storing files 
  dir.create(file.path(outPath, "interpolated"))
   
  # apply per gear per vessel (otherwise risk for 'out of memory')
    for(gr in towed_gears){
      tacsatp_gr        <- tacsatp[!is.na(tacsatp$LE_GEAR) & tacsatp$LE_GEAR==gr,]
      tacsatp_gr$VE_REF <- factor(tacsatp_gr$VE_REF)
   
      for(vid in levels(tacsatp_gr$VE_REF)){
          cat(paste("apply on ", vid, " and ", gr, "\n", sep=""))
  
          tacsatp_gr_vid <- tacsatp_gr[tacsatp_gr$VE_REF %in% vid,]
          if(nrow(tacsatp_gr_vid)>3) {
 
          #Interpolate according to the cubic-hermite spline interpolation
          interpolationcHs <- interpolateTacsat(tacsatp_gr_vid,
                            interval=60,
                            margin=10, # i.e. will make disconnected interpolations if interval out of the 50 70min range
                            res=100,
                            method="cHs",
                            params=list(fm=0.2,distscale=20,sigline=0.2,st=c(2,6)),   # rmenber that st not in use....
                            headingAdjustment=0,
                            fast=FALSE)

          #Make a picture of all interpolations first
          #Get the ranges of the total picture
          #ranges <- do.call(rbind,lapply(cHs,function(x){return(apply(x[-1,],2,range))}))
          #xrange <- range(ranges[,"x"])
          #yrange <- range(ranges[,"y"])
 
          #plot(tacsatp_gr_vid$SI_LONG, tacsatp_gr_vid$SI_LATI, 
          #       xlim=xrange,ylim=yrange,pch=19,col="blue",xlab="Longitude",ylab="Latitude")
          #for(iInt in 1:length(cHs)){
          #lines(cHs[[iInt]][-1,1],cHs[[iInt]][-1,2])}

              
          #Convert the interpolation to tacsat style data
          tacsatp_gr_vid$SI_TIME <- as.character(tacsatp_gr_vid$SI_TIME) # debug fba
          tacsatInt_gr_vid       <- interpolation2Tacsat(interpolationcHs, tacsatp_gr_vid) 
          # => note that equalDistance() is encapsulated in interpolation2Tacsat()
          # Each interpolation is splitted into 10 equally spaced points (including the start and the end point). 
          # In total 8 new points are added per interpolation.
          
                                
          # visual check
          plot(tacsatInt_gr_vid$SI_LONG, tacsatInt_gr_vid$SI_LATI, pch=".", col=2)
          points(tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE!=2,'SI_LONG'], 
                       tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE!=2,'SI_LATI'], col=3, pch=16) # steaming (remaining ones (because we are conservative here))
          points(tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE==2,'SI_LONG'], 
                       tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE==2,'SI_LATI'], col=2, pch=16) # fishnig

  
        # What is the distance traveled within each of these interpolations?
        sum(distanceInterpolation(interpolationcHs))

        #compute the swept area from the interpolated distance and the gear width
        #.......
         tacsatInt_gr_vid$SWEPT_AREA_KM2 <- distance(c(tacsatInt_gr_vid$SI_LONG[-1],0),  c(tacsatInt_gr_vid$SI_LATI[-1],0),
                                                       tacsatInt_gr_vid$SI_LONG,  tacsatInt_gr_vid$SI_LATI)*tacsatInt_gr_vid$LE_GEAR_WIDTH
          
       
       # save (a file by gr_vid)
       save(tacsatInt_gr_vid, file=file.path(outPath, "interpolated", 
          paste("tacsatSweptArea_",vid, "_", gr, ".RData", sep="")))
     } # end if enough records
    } # end vid
  } # end gr
 
 
 </code>  









   - buffer area (passive gear)

<code>  
all_gears      <- levels(tacsatp$LE_GEAR)
passive_gears  <- all_gears[!all_gears %in% towed_gears]

  # apply per gear per vessel (otherwise risk for 'out of memory')
    for(gr in passive_gears){
      tacsatp_gr        <- tacsatp[!is.na(tacsatp$LE_GEAR) & tacsatp$LE_GEAR==gr,]
      tacsatp_gr$VE_REF <- factor(tacsatp_gr$VE_REF)
   
      for(vid in levels(tacsatp_gr$VE_REF)){
          cat(paste("apply on ", vid, " and ", gr, "\n", sep=""))

          tacsatp_gr_vid <- tacsatp_gr[tacsatp_gr$VE_REF %in% vid,]
          tacsatp_gr_vid <- tacsatp_gr_vid[tacsatp_gr_vid$SI_STATE=='f',] # keep fishing pings only
      
         # compute a buffer area around each fishing location
         # and assign the area to the point
         # the radius of the circle is given by: area= pi*(R)^2 = pi*(C/(2*pi))^2
         # with C the length of the nets, or the nb of nets * length of a unit net
         # for seiners and netters respectively
         C                            <- tacsatp_gr_vid$LE_GEAR_WIDTH
         tacsatp_gr_vid$SWEPT_AREA_KM2 <- pi*(C/(2*pi))^2 

         # save (a file by gr_vid)
         save(tacsatInt_gr_vid, file=file.path(outPath, "interpolated", 
           paste("tacsatSweptArea_",vid, "_", gr, ".RData", sep="")))

      }
   } 

</code>  










  * bound all the files to one
  
<code>  
   # after having subsetted per gear per vessel (because risk of 'out of memory')
    lst <- list(NULL) ; count <- 0
    for(gr in levels(tacsatp$LE_GEAR)){
      tacsatp_gr        <- tacsatp[!is.na(tacsatp$LE_GEAR) & tacsatp$LE_GEAR==gr,]
      tacsatp_gr$VE_REF <- factor(tacsatp_gr$VE_REF)
   
      for(vid in levels(tacsatp_gr$VE_REF)){
          count <- count+1
        
          cat(paste("load ", vid, " and ", gr, "\n", sep=""))
          er <- try(load(file.path(outPath, "interpolated", 
                paste("tacsatSweptArea_",vid, "_", gr, ".RData", sep=""))),
                silent=TRUE)
          if(class(er)=="try-error"){
          count <- count -1
          } else{      
          lst[[count]] <-  tacsatInt_gr_vid
          }
     
      }
      
    }
    tacsatp <- do.call("rbind", lst) 
    # save 
    save(tacsatp, file=file.path(outPath, paste("tacsatSweptArea.RData", sep="")))
 
</code>  






  * labelling each haul  

<code>  
# assign an identifier in 'HL_ID' to each of the fishing sequences
# (based on SI_STATE, assuming the "h", "f", "s" coding)
# (useful to count them in a grid...)
tacsatp <- labellingHauls(tacsatp)  
gc(reset=TRUE)
</code>  







  * link habitat map to vms




    * shapefile 

<code>  
  library(maptools) 
 
  # load a habitat map shape file
  habitat_map           <- readShapePoly(file.path(polPath,"sediment_lat_long"),
                                         proj4string=CRS("+proj=longlat +ellps=WGS84"))

  sh_coastlines            <- readShapePoly(file.path(polPath,"francois_EU"))
 
  
  load(file.path(outPath, "tacsatSweptArea.RData")) # get 'tacsatp' with all data 
  #....or load only one instance eg load(file.path(outPath, "interpolated","tacsatSweptArea_DNK000005269_OTB.RData"))
  #tacsatp <- tacsatInt_gr_vid
  
  coord <-  tacsatp[, c('SI_LONG', 'SI_LATI')]
  names(habitat_map) # return the name of the coding variable
 
  #Turn the polygons into spatial polygons
  sp <- SpatialPolygons(habitat_map@polygons)
  projection(sp) <-  CRS("+proj=longlat +ellps=WGS84")

  #Turn the point into a spatial point
  spo <- SpatialPoints(coordinates(data.frame(SI_LONG=coord[,1],
                                             SI_LATI=coord[,2])))
  projection(spo) <-  CRS("+proj=longlat +ellps=WGS84")

  #Use the magic 'over' function to see in which polygon it is located
  idx <- over(spo,sp); print(idx)
  tacsatp$SUBSTRATE <- habitat_map$BAL_CODE[idx] 
 
  # plot
  plot(habitat_map, xlim=c(11,14), ylim=c(55,56))
  axis(1) ; axis(2, las=2) ; box()
  points(tacsatp[, c("SI_LONG","SI_LATI")], col=tacsatp$SUBSTRATE, pch=".")
  #plot(sh_coastlines, add=TRUE)

  # save
  savePlot(filename=file.path(outPath, "VMSpingsAttachedToSedimentMap.jpeg"), type="jpeg")
</code>  

 
 
 
 
 
 
 
 
 
 
 
 
    * raster

<code>
  
  sh_coastlines            <- readShapePoly(file.path(polPath,"francois_EU"))
 
  ## use point-raster overlay.......
  library(raster)
  landscapes       <- raster(file.path(polPath, "landscapes.tif"))    # probably need an update of rgdal here....
  newproj          <- "+proj=longlat +datum=WGS84"
  landscapes_proj  <- projectRaster(landscapes, crs=newproj)
  
  save(landscapes_proj, file=file.path(polPath, "landscapes_proj.RData"))
  
  load(file.path(polPath, "landscapes_proj.RData")) 
 
  load(file.path(outPath, "tacsatSweptArea.RData")) # get 'tacsatp' with all data 
  #....or load only one instance eg load("C:\\merging\\BENTHIS\\outputs\\interpolated\\tacsatSweptArea_DNK000005269_OTB.RData"))
  #tacsatp <- tacsatInt_gr_vid

  
  coord <- cbind(x=anf(tacsatp$SI_LONG), y=anf(tacsatp$SI_LATI))
  
  dd <- extract (landscapes_proj, coord[,1:2]) # get the landscape on the coord points!

  coord <- cbind(coord,  landscapes_code=cut(dd, breaks=c(0,100,200,300,400,500,600)))

  tacsatp <- cbind(tacsatp, landscapes_code= coord[,'landscapes_code'])
  
  # plot and save...
  plot(landscapes_proj, xlim=c(10,14), ylim=c(54.5,56.5))
  plot(sh_coastlines,  xlim=c(10,14), ylim=c(54.5,56.5), add=TRUE)  # better for plotting the western baltic sea coastline!
  points(coord[,"x"], coord[,"y"], col=coord[,"landscapes_code"], pch=".", cex=1)

  # save
  savePlot(filename=file.path(outPath, "VMSpingsAttachedToLandscapeMap.jpeg"), type="jpeg")
  
</code>  




  * severity of activity: read in a look-up table (from interviews / experimental studies)


<code>  
  ## by gear/metier by habitat
  ## (i.e. a mutiplying factor in relative terms)
     
  # create a fake input file to show the required format
  dd <- tacsatp[!duplicated(data.frame(tacsatp$VE_REF,tacsatp$LE_GEAR, tacsatp$LE_MET)), ] 
  fake_gear_metier_habitat_severity_table <- dd[,c('VE_REF', 'LE_GEAR', 'LE_MET')]
  fake_gear_metier_habitat_severity_table <- cbind(fake_gear_metier_habitat_severity_table, HAB_SEVERITY=1)
  gear_metier_habitat_severity_table  <- fake_gear_metier_habitat_severity_table  
  gear_metier_habitat_severity_table  <-   gear_metier_habitat_severity_table[complete.cases( gear_metier_habitat_severity_table),] 
  save(gear_metier_habitat_severity_table,   file=paste(dataPath,"gear_metier_habitat_severity_table.RData",   sep=""))
  
  # load a table for HAB_SEVERITY per vid LE_REF per gr LE_GEAR per met LE_MET
  load(file.path(dataPath, "gear_metier_habitat_severity_table.RData"))
  tacsatp <- merge(tacsatp, gear_metier_habitat_severity_table) 
  save(tacsatp,   file=paste(outPath,"tacsatMergedHabSeverity.RData",   sep=""))
</code>  


  * pressure: weigh the swept area by the severity

<code>  
tacsatp$pressure <- tacsatp$HAB_SEVERITY * tacsatp$SWEPT_AREA_KM2
</code>  



  * define grid
    * mid-point polygon distance distribution (to help defining a suitable grid resolution)
<code>  
</code>  


 





    * random process of fishing activity (to help defining a suitable grid resolution)

<code>  
</code>  






  * maps + sum / average different grids
  using a quick gridding code at various resolution.

    * For example, grid the swept area, or the number of hauls, or the fishing pressure, etc.
<code>  
   ##-----------------------------------------------------------------------------
   # 
    sh1 <- readShapePoly(file.path(polPath,"francois_EU"))

   
    ### the swept area-------------------------------------------
    what <- "SWEPT_AREA_KM2"
    #what <- "HL_ID"
    #what <- "pressure"
    #a_func <- function(x) {unique(length(x))} # for HL_ID, to be tested.
    a_func <- "sum"
    this <- tacsatInt_gr_vid [,c('SI_LONG', 'SI_LATI', what)]
    colnames(this) <- c('x', 'y', 'what')

    #dx <- 6.25  # a finer grid will be produced if a higher value is put here
    dx <- 12  # a finer grid will be produced if a higher value is put here
   
    # retrieve the geo resolution, for info
    long <- seq(1,15,by=0.01)
    res_long <- diff( long [1+which(diff(round(long*dx)/dx)!=0)] )
    res_lat <- diff( long [1+which(diff(round(long*dx/2)/dx/2)!=0)] )


   
     the_breaks <-  c(0,1,2,4,8,16,32,64,128, 256, 512)^0.9 
    # a quick gridding method...
    this$round_long <- round(as.numeric(as.character(this$x))*dx) 
    this$round_lat  <- round(as.numeric(as.character(this$y))*dx*2)
    background <- expand.grid(
                              what=0,
                              x=0,
                              y=0,
                              round_long=seq(range(this$round_long)[1], range(this$round_long)[2]),
                              round_lat=seq(range(this$round_lat)[1], range(this$round_lat)[2])
                              )
    this <- rbind(this, background)
    the_points <- tapply(this$what,
                  list(this$round_lat, this$round_long), a_func)

    xs <- (as.numeric(as.character(colnames(the_points)))/dx)
    ys <- (as.numeric(as.character(rownames(the_points)))/(dx*2))
    graphics:::image(
     x=xs,
     y=ys,
     z= t(the_points)  ,
     breaks=c(the_breaks),
     col = terrain.colors(length(the_breaks)-1),
     useRaster=FALSE,
     xlab="",
     ylab="",
     axes=FALSE,
     xlim=range(xs), ylim=range(ys),
     add=FALSE
     )
    title("")

    plot(sh1, add=TRUE, col=grey(0.7))
    legend("topright", fill=terrain.colors(length(the_breaks)-1),
             legend=round(the_breaks[-1],1), bty="n", cex=0.8, ncol=2, title="")                   
    box()
    axis(1)
    axis(2, las=2)

    mtext(side=1, "Longitude", cex=1, adj=0.5, line=2)
    mtext(side=2, "Latitude", cex=1, adj=0.5, line=2)
    #mtext(side=3, "(a)", cex=1.5, adj=0, line=1)

    points (tacsatInt_gr_vid [,c('SI_LONG', 'SI_LATI')], pch=".", col="white")

    # save
    savePlot(filename=file.path(outPath, "GriddedSweepAreaExample.jpeg"), type="jpeg")

</code>  
 
 
 [[Image:http://code.google.com/p/vmstools/source/browse/wiki/GriddedSweepAreaExample.jpeg|thumb|center|upright=2.0|alt=Gridded Swept Area. 
 Gridded Swept Area example in km2 for one vessel in the Baltic Sea. | Original VMS pings are overlaid]] 


or using createGrid()
<code>  
</code>  

...and stack some layers making use of mosaic() from raster layers.

<code>  
# from ascgridfile eg. returned by VMSGridCreate()
# TO DO:
dd <- 
nn <- 
fun1  <-  function(x)  { x[ is.na(x)]  <- 0;  return(x)  }            # remove NA such zero
dd <-  calc(dd,  fun1)
nn <-  calc(nn,  fun1)
a_stack <-mosaic(dd, nn, na.rm=TRUE, fun = sum, keepres=TRUE) 
</code>  


  * non-vms maps. For non VMS-equipped vessels, the mapping of the fishing effort
  can be generated at the ICES rectangle resolution as a proxy of the fishing pressure on the benthic habitats 

<code> 
# TO DO from e.g. plotTools()
#....
# TO DO: stack several layers with various geographical resolutions 
</code>  





  * testing

<code>  
</code>


  